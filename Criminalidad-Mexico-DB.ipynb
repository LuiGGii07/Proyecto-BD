{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se instalan las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pysparkNote: you may need to restart the kernel to use updated packages.\n",
      "  Using cached pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting py4j==0.10.9.5\n",
      "  Using cached py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845525 sha256=bce3a1d4541f45f8bb516697beec9ce253886774ffb8d4cfb3c48fe093888cd5\n",
      "  Stored in directory: c:\\users\\luisz\\appdata\\local\\pip\\cache\\wheels\\51\\c8\\18\\298a4ced8ebb3ab8a7d26a7198c0cc7035abb906bde94a4c4b\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sparkNote: you may need to restart the kernel to use updated packages.\n",
      "  Using cached spark-0.2.1.tar.gz (41 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: spark\n",
      "  Building wheel for spark (setup.py): started\n",
      "  Building wheel for spark (setup.py): finished with status 'done'\n",
      "  Created wheel for spark: filename=spark-0.2.1-py3-none-any.whl size=58767 sha256=c7be00626eb3ffe1af10d5ced6961157461d2bb3497a470e9b76cfcf9acdf762\n",
      "  Stored in directory: c:\\users\\luisz\\appdata\\local\\pip\\cache\\wheels\\bc\\0f\\6c\\b41528ca0fd4d46513185e90da91bc1c484bba6138641c5a62\n",
      "Successfully built spark\n",
      "Installing collected packages: spark\n",
      "Successfully installed spark-0.2.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se importan las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "error",
     "timestamp": 1669707229318,
     "user": {
      "displayName": "Luis Carlos Quijada",
      "userId": "06484693357558489758"
     },
     "user_tz": 420
    },
    "id": "q-b-XEAbTU3w",
    "outputId": "7ab2afb8-3ea4-488d-8bc2-f60ad175a506"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import spark\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se inicia la sesión local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Luigiii.Luis:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test_spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x22f1e18e280>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init() \n",
    "spark = SparkSession.builder.appName(\"Test_spark\").master(\"local[*]\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se crea una la variable df para el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('C:/Users/luisz/OneDrive/Desktop/mexico.csv', sep=',', header=True)\n",
    "df.createOrReplaceTempView ('registros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ciclo donde se ejecuta el programa para elegir las diferentes consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while not consulta == \"salir\":\n",
    "    if consulta != \"salir\" :\n",
    "      if consulta == 1:\n",
    "        print(\"Indica el año que deseas consultar\")\n",
    "        año = input()\n",
    "        año = \"Reporte_\" + año\n",
    "        print(\"Top 5 Estados con mayor indice de delincuencia\")\n",
    "        spark.sql(f\"\"\"SELECT * FROM Mexico ORDER BY '{año}' desc limit 5\"\"\").show(5, truncate=False)\n",
    "      if consulta == 2 :\n",
    "        print(\"Indica el estado que deseas consultar\")\n",
    "        estado = input()\n",
    "        print(\"Indica el año que deseas consultar\")\n",
    "        año = input()\n",
    "        año = \"Reporte_\" + año\n",
    "        print(\"Indice de delincuencia de un estado de interes un año de interes\")\n",
    "        spark.sql(f\"\"\"SELECT Entidad, '{año}'  FROM Mexico Where Entidad = '{estado}' \"\"\").show(1, truncate=False)\n",
    "      if consulta == 3 :\n",
    "        print(\"Indica el estado que deseas consultar\")\n",
    "        estado = input()\n",
    "        print(\"Indice de delincuencia de un estado de interes todos los años registrados\")\n",
    "        spark.sql(f\"\"\"SELECT * FROM Mexico Where Entidad = '{estado}' \"\"\").show(1, truncate=False)\n",
    "      if consulta == 4 :\n",
    "        print(\"Consultar los 32 registros completos de los estados (4)\")\n",
    "        spark.sql(f\"\"\"SELECT * FROM Mexico \"\"\").show(32, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realiza la consulta que el usuario haya elegido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print('Hola, aquí es posible hacer consultas sobre:')\n",
    "    print('Top 5 Estados con mayor indice de delincuencia (1)')\n",
    "    print('Indice de delincuencia de un estado de interes un año de interes (2)')\n",
    "    print('Indice de delincuencia de un estado de interes todos los años registrados (3)')\n",
    "    print('Consultar los 32 registros completos de los estados (4)')\n",
    "    print('o escribe salir')\n",
    "    consulta = input()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMKiE1gCVDkjdK8fD/NxdO5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
